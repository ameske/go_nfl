#!/usr/bin/python

'''
scrapeSchedule.py

Parses the DOM of www.nfl.com/schedules to load the database with the
matchups for the current season.

Work required each season:
  1. Update 'schedule_url' to the current root URL for the NFL's schedules.
  2. Change the parameter to scrape() to the current year
  3. Change the file name to the current year

@author: Kyle Ames
@date: August 17, 2014
'''
from bs4 import BeautifulSoup
import urllib2
import datetime
import re
import json

schedule_url = 'http://www.nfl.com/schedules/2014/REG'

def is_away_team(css_class):
  return css_class == "team-name away lost" or css_class == "team-name away "

def is_home_team(css_class):
  return css_class == "team-name home lost" or css_class == "team-name home "

def scrape(year):
    games = []

    for week_no in range(1, 18):
        
        # OPEN UP THE HTML FOR EACH WEEK
        print 'Scraping Week: ' + str(week_no) 
        page = urllib2.urlopen(schedule_url + str(week_no))
        scheduleHTML = BeautifulSoup(page.read())
        
        # PARALLEL LISTS OF AWAY, HOME, TIME
        away_teams  = [ str(tag.string) for tag in scheduleHTML.find_all(class_="team-name away ") ]
        print len(away_teams)
        home_teams  = [ str(tag.string) for tag in scheduleHTML.find_all(class_="team-name home ") ]
        print len(home_teams)
        times       = [ str(tag.string) for tag in scheduleHTML.find_all(class_="time") ]
        dates       = [ str(tag.find_previous(class_="schedules-list-date").contents[1].strings.next()).replace(',', '') for tag in scheduleHTML.find_all(class_="list-matchup-row-team") ]

        #  MERGE times and dates AND THEN BRING BACK INTO A DATETIME LIST
        dates_times = zip(dates, times)
        dates       = [ dt[0] + " 2013 " + dt[1] + " PM EST" for dt in dates_times]
        datetimes = [ datetime.datetime.strptime(date_string, '%A %B %d %Y %I:%M %p %Z') for date_string in dates ]
        
        # CREATE MATCHUP TUPLES AND CONVERT THEM INTO A DICTIONARY FOR JSON
        matchups = zip(away_teams, home_teams, datetimes)      
        for matchup in matchups:
            print matchup
            d = {
                    "year": year,
                    "week": week_no,
                    "away": matchup[0],
                    "home": matchup[1],
                    "date": matchup[2].isoformat(),
            }
            games.append(d)

    return games

def main():
    schedule = scrape(2014)
    fd = open('2014.json', 'w')
    print json.dumps(schedule)
    #fd.write(json.dumps(schedule)) 
    #fd.close()
    
if __name__=='__main__':
    main()
    
